# app.py
from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
import numpy as np
import pickle # For loading your trained model
import os # To check for file existence

app = Flask(__name__)
# Enable CORS for all origins, allowing your frontend to communicate with this backend
CORS(app)

# --- Machine Learning Model and Preprocessing Components ---
# IMPORTANT:
# 1. Ensure 'linear_regression_model.pkl' and 'one_hot_encoder.pkl' are in the same directory as this Flask script.
#    These files should be generated by saving your trained LinearRegression model and fitted OneHotEncoder.
# 2. Your model should have been trained with 'sex_code' (e.g., 0 for female, 1 for male).
#    The frontend has been updated to send 'sex'.

model = None
one_hot_encoder = None

# Define the paths to your model and encoder files
MODEL_PATH = 'linear_regression_model.pkl'
ENCODER_PATH = 'one_hot_encoder.pkl'

# --- VERIFICATION POINT 1: Model and Encoder Loading ---
# Check your Flask server's console output carefully when it starts.
# You MUST see "loaded successfully!" messages for both.
# If not, ensure the .pkl files are in the same directory as app.py and are not corrupted.
if os.path.exists(MODEL_PATH):
    try:
        model = pickle.load(open(MODEL_PATH, 'rb'))
        print(f"Model '{MODEL_PATH}' loaded successfully!")
    except Exception as e:
        print(f"ERROR: Failed to load model from '{MODEL_PATH}': {e}. Using a dummy prediction function.")
        model = None # Ensure model is None if loading fails
else:
    print(f"WARNING: Model file '{MODEL_PATH}' not found. Using a dummy prediction function.")

if os.path.exists(ENCODER_PATH):
    try:
        one_hot_encoder = pickle.load(open(ENCODER_PATH, 'rb'))
        print(f"OneHotEncoder '{ENCODER_PATH}' loaded successfully!")
    except Exception as e:
        print(f"ERROR: Failed to load OneHotEncoder from '{ENCODER_PATH}': {e}. Region encoding will not work correctly.")
        one_hot_encoder = None # Ensure encoder is None if loading fails
else:
    print(f"WARNING: OneHotEncoder file '{ENCODER_PATH}' not found. Region encoding will not work correctly.")


# Dummy prediction function for demonstration if no model or encoder is loaded
def dummy_predict(data):
    """
    A placeholder prediction function used if the actual model or encoder fails to load.
    It performs a simple calculation based on input features.
    This is NOT your trained model's prediction.
    """
    age = data.get('age', 0)
    bmi = data.get('bmi', 0)
    children = data.get('children', 0)
    smoker = data.get('smoker', False) # Expects boolean
    sex = data.get('sex', 'female') # Expects string 'male' or 'female'
    region = data.get('region', 'northeast') # Default region

    base_charge = 5000
    charge = base_charge + (age * 100) + (bmi * 50) + (children * 200)

    if smoker: # Directly use boolean
        charge += 10000 # Smoker adds a significant charge

    if sex.lower() == 'male': # Consider sex in dummy prediction
        charge += 1000 # Males might have slightly higher base rates in some datasets
    elif sex.lower() == 'female':
        charge += 0 # No additional charge for female in this dummy model

    # Add region specific charges for dummy prediction
    if region == 'southeast':
        charge += 500
    elif region == 'northeast':
        charge += 300
    elif region == 'northwest':
        charge += 200
    elif region == 'southwest':
        charge += 100

    # Add some random noise to make it seem less static
    charge += np.random.uniform(-500, 500)
    return max(0, charge) # Ensure charges are not negative

@app.route('/predict', methods=['POST'])
def predict():
    """
    API endpoint to receive user input and return medical charge prediction.
    """
    try:
        data = request.get_json(force=True) # Get JSON data from the request
        print("Received data for prediction:", data)

        # Extract features from the received JSON data
        age = data['age']
        bmi = data['bmi']
        smoker = data['smoker'] # This is boolean from frontend
        children = data['children']
        region = data['region']
        sex = data['sex'] # Now 'sex' is expected from the frontend


        predicted_charges = 0
        if model and one_hot_encoder:
            # --- Data Preprocessing for your Model ---
            # --- VERIFICATION POINT 2: Consistent Preprocessing ---
            # Ensure these transformations match EXACTLY what you did during training.
            # Example: if you scaled numerical features, do it here with the SAME scaler.

            # Convert smoker boolean to 0 or 1
            smoker_code = 1 if smoker else 0

            # Convert sex string to 0 or 1 (assuming 0 for female, 1 for male as per common encoding)
            sex_code = 1 if sex.lower() == 'male' else 0

            # Create a dictionary for all features
            input_features_dict = {
                'age': age,
                'bmi': bmi,
                'children': children,
                'smoker_code': smoker_code,
                'sex_code': sex_code,
            }

            # Prepare region for one-hot encoding
            region_df = pd.DataFrame([[region]], columns=['region'])

            # Apply one-hot encoding to the region using the loaded encoder
            # .transform returns a sparse matrix by default, .toarray() converts it to dense numpy array
            region_encoded_array = one_hot_encoder.transform(region_df).toarray()

            # Get feature names for the one-hot encoded columns from the encoder
            region_cols = one_hot_encoder.get_feature_names_out(['region'])

            # Add one-hot encoded region features to the dictionary
            for i, col_name in enumerate(region_cols):
                input_features_dict[col_name] = region_encoded_array[0, i]

            # --- VERIFICATION POINT 3: Consistent Feature Order ---
            # This order MUST EXACTLY MATCH the column order used when you trained your model.
            # print(X_final.columns) from your training script to verify this list.
            expected_feature_order = [
                'age', 'bmi', 'children', 'smoker_code', 'sex_code',
                'region_northeast', 'region_northwest', 'region_southeast', 'region_southwest'
            ]
            # Ensure the input_features_dict contains all expected keys,
            # and create DataFrame in the exact order.
            final_input_df = pd.DataFrame([input_features_dict], columns=expected_feature_order)

            # print("Final input DataFrame for prediction:\n", final_input_df) # Uncomment for debugging

            # Make prediction using the loaded model
            predicted_charges = model.predict(final_input_df)[0]

            # If you used a target scaler (e.g., StandardScaler) during training for 'charges',
            # you would inverse transform the prediction here using the *saved* scaler:
            # predicted_charges = target_scaler.inverse_transform([[predicted_charges]])[0][0]
        else:
            # If model or encoder loading failed, use the dummy prediction function
            print("Using dummy prediction because model/encoder not loaded.")
            predicted_charges = dummy_predict(data) # Pass the original data dict

        print(f"Predicted charges: {predicted_charges}")
        return jsonify({'predicted_charges': predicted_charges})

    except KeyError as ke:
        print(f"ERROR: Missing data key: {ke}. Request data: {request.get_json(force=True, silent=True)}")
        return jsonify({'error': f"Missing data: '{ke}'. Please ensure all required fields (age, bmi, smoker, children, region, sex) are sent."}), 400
    except Exception as e:
        print(f"ERROR: An unexpected error occurred during prediction: {e}")
        # Always return a JSON response, even on error
        return jsonify({'error': f"An internal server error occurred: {str(e)}. Please check server logs."}), 500 # Return 500 for internal errors

# Sample Dataset for the /dataset endpoint
# This data is static and for display, not directly used in the prediction logic.
sample_data = [
    {"age": 19, "sex": "female", "bmi": 27.9, "children": 0, "smoker": True, "region": "southwest", "charges": 16884.924},
    {"age": 18, "sex": "male", "bmi": 33.77, "children": 1, "smoker": False, "region": "southeast", "charges": 1725.5523},
    {"age": 28, "sex": "male", "bmi": 33.0, "children": 3, "smoker": False, "region": "southeast", "charges": 4449.462}, # This is your test case!
    {"age": 33, "sex": "male", "bmi": 22.705, "children": 0, "smoker": False, "region": "northwest", "charges": 21984.47061},
    {"age": 32, "sex": "male", "bmi": 28.88, "children": 0, "smoker": False, "region": "northwest", "charges": 3866.8552},
    {"age": 31, "sex": "female", "bmi": 25.74, "children": 0, "smoker": False, "region": "southeast", "charges": 3756.6216},
    {"age": 46, "sex": "female", "bmi": 33.44, "children": 1, "smoker": False, "region": "southeast", "charges": 8240.5896},
    {"age": 37, "sex": "female", "bmi": 27.74, "children": 3, "smoker": False, "region": "northwest", "charges": 7281.5056},
    {"age": 37, "sex": "male", "bmi": 29.83, "children": 2, "smoker": False, "region": "northeast", "charges": 6406.4107},
    {"age": 60, "sex": "female", "bmi": 25.84, "children": 0, "smoker": False, "region": "northwest", "charges": 28923.43229}
]

@app.route('/dataset', methods=['GET'])
def get_dataset():
    """
    API endpoint to return the sample dataset.
    """
    print("Serving sample dataset.")
    return jsonify(sample_data)

if __name__ == '__main__':
    # Run the Flask app
    # IMPORTANT: For local development, use debug=True.
    # For production, set debug=False and use a production-ready WSGI server like Gunicorn.
    app.run(debug=True, port=5000)